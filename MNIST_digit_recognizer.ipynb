{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvScD8DRvw0hHEgoS3FCFE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thetachenlab/Neural-Network-Bootcamp/blob/main/MNIST_digit_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Roq6PtCI22yN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "data = pd.read_csv('sample_data/mnist_train_small.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "data = np.array(data)\n",
        "m, n = data.shape\n",
        "print(m,n)\n",
        "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
        "\n",
        "data_dev = data[0:1000].T\n",
        "\n",
        "Y_dev = data_dev[0]\n",
        "X_dev = data_dev[1:n]\n",
        "X_dev = X_dev / 255.\n",
        "\n",
        "data_train = data[1000:m].T\n",
        "Y_train = data_train[0]\n",
        "X_train = data_train[1:n]\n",
        "X_train = X_train / 255.\n",
        "_,m_train = X_train.shape\n",
        "\n",
        "print(data_train.shape)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "jA_mnm9y7j-E",
        "outputId": "b956a9f4-c7cf-4685-eef8-0b05be61aebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19999 785\n",
            "(785, 18999)\n",
            "(784, 18999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* ${X_j}= [784\\times m]$ where $m$ is the number of training dataset.\n",
        "* ${Y_j}= [10\\times m]$ where $m$ is the number of training dataset.\n",
        "\n",
        "First layer\n",
        "* $W^{[1]}_{ij}= [10\\times 784]$\n",
        "* $B^{[1]}_i = [10\\times 1]$\n",
        "* ${Z^{[1]}_i}= [10\\times m]$\n",
        "* ${A^{[1]}_i}= [10\\times m]$\n",
        "\n",
        "Second layer\n",
        "* $W^{[2]}_{ij}= [10\\times10]$\n",
        "* $B^{[2]}_i = [10\\times 1]$\n",
        "* ${Z^{[2]}_i}= [10\\times m]$\n",
        "* ${A^{[2]}_i}= [10\\times m]$\n",
        "\n",
        "Forward propagation:\n",
        "\\begin{align}\n",
        "Z^{[1]}_i &= \\sum_j^{784} W^{[1]}_{ij}X_j+B^{[1]}_i \\\\\n",
        "A^{[1]}_i &= \\text{ReLU} (Z^{[1]}_i) \\\\\n",
        "Z^{[2]}_i &= \\sum_j^{10} W^{[2]}_{ij}A^{[1]}_j+B^{[2]}_i \\\\\n",
        "A^{[2]}_i &= \\text{softmax} (\\{Z^{[2]}_i\\}) \\\\\n",
        "\\end{align}\n",
        "where $\\text{softmax}(\\{Z^{[2]}_i\\})=e^{Z^{[2]}_i}/\\sum_j e^{Z^{[2]}_j}$.\n",
        "\n",
        "Cross-entropy loss\n",
        "\\begin{equation}\n",
        "\\mathcal{L} = -\\sum_i Y_i\\log(A^{[2]}_i)\n",
        "\\end{equation}\n",
        "\n",
        "Backward propagation\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial A^{[2]}_i}=-\\frac{Y_i}{A^{[2]}_i}\n",
        "\\end{align}\n",
        "\\begin{align}\n",
        "\\frac{\\partial A^{[2]}_i}{\\partial Z^{[2]}_j}&=A^{[2]}_i(1-A^{[2]}_i)\\delta_{ij}-A^{[2]}_iA^{[2]}_j(1-\\delta_{ij}) \\\\\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial Z^{[2]}_j}&=\\sum_i\\frac{\\partial\\mathcal{L}}{\\partial A^{[2]}_i}\\frac{\\partial A^{[2]}_i}{\\partial Z^{[2]}_j}\\\\\n",
        "&=-\\sum_i\\frac{Y_i}{A^{[2]}_i} [A^{[2]}_i(1-A^{[2]}_i)\\delta_{ij}-A^{[2]}_iA^{[2]}_j(1-\\delta_{ij})]\\\\\n",
        "&=-\\sum_i{Y_i} [(1-A^{[2]}_i)\\delta_{ij}-A^{[2]}_j(1-\\delta_{ij})]\\\\\n",
        "&=-{Y_j}(1-A^{[2]}_j) + A^{[2]}_j - {Y_j}A^{[2]}_j\\\\\n",
        "&=-{Y_j}+ A^{[2]}_j\n",
        "\\end{align}\n",
        "(Note that $\\sum {Y_i}=1$)\n",
        "so $\\delta Z^{[2]}=A^{[2]} -Y$.\n",
        "\n",
        "---\n",
        "\n",
        "> Questions: Why we average over the training data to build $\\delta W^{[2]}$ here?\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial Z^{[2]}_i}{\\partial W^{[2]}_{ij}}&=A^{[1]}_j\\\\\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial W^{[2]}_{ij}}&=\\frac{\\partial\\mathcal{L}}{\\partial Z^{[2]}_i}\\frac{\\partial Z^{[2]}_i}{\\partial W^{[2]}_{ij}}\\\\\n",
        "&=(-{Y_i}+ A^{[2]}_i)\\cdot A^{[1]}_j\n",
        "\\end{align}\n",
        "so $\\delta W^{[2]}=\\frac{1}{m} \\delta Z^{[2]}\\cdot A^{[1]T}$\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial Z^{[2]}_i}{\\partial B^{[2]}_{j}}&=\\delta_{ij}\\\\\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial B^{[2]}_{i}}&=\\frac{\\partial\\mathcal{L}}{\\partial Z^{[2]}_i}\\frac{\\partial Z^{[2]}_i}{\\partial B^{[2]}_{i}}\\\\\n",
        "&=-{Y_i}+ A^{[2]}_i\n",
        "\\end{align}\n",
        "so $\\delta B^{[2]}=\\frac{1}{m}\\sum \\delta Z^{[2]}$.\n",
        "\n",
        "\n",
        "---\n",
        "\\begin{align}\n",
        "\\frac{\\partial Z^{[2]}_j}{\\partial A^{[1]}_k}&=W^{[2]}_{jk}\\\\\n",
        "\\frac{\\partial A^{[1]}_k}{\\partial Z^{[1]}_k}&=\\Theta(Z^{[1]}_k)\\\\\n",
        "\\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial\\mathcal{L}}{\\partial Z^{[1]}_k}&=\\sum_{j}\\frac{\\partial\\mathcal{L}}{\\partial Z^{[2]}_j}\\frac{\\partial Z^{[2]}_j}{\\partial A^{[1]}_k}\\frac{\\partial A^{[1]}_k}{\\partial Z^{[1]}_k}\\\\\n",
        "&=\\sum_{j}(-{Y_j}+ A^{[2]}_j)W^{[2]}_{jk}\\Theta(Z^{[1]}_k)\n",
        "\\end{align}\n",
        "Note that $\\sum_j$ is inner product and the $k$ index is element-wise muliplication. So $\\delta Z^{[1]} = W^{[2]T}\\cdot\\delta Z^{[2]} * \\Theta(Z^{[1]})$\n",
        "\n",
        "\n",
        "Since $Z$ in the first second layers are both linear, we have $\\delta W^{[1]}=\\frac{1}{m} \\delta Z^{[1]}\\cdot A^{[0]T}$ where $A^{[0]}\\equiv X$ and $\\delta B^{[1]}=\\frac{1}{m}\\sum \\delta Z^{[1]}$."
      ],
      "metadata": {
        "id": "47wDSEmsuvhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params():\n",
        "    W1 = np.random.rand(10, 784) - 0.5\n",
        "    b1 = np.random.rand(10, 1) - 0.5\n",
        "    W2 = np.random.rand(10, 10) - 0.5\n",
        "    b2 = np.random.rand(10, 1) - 0.5\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def ReLU(Z):\n",
        "    return np.maximum(Z, 0)\n",
        "\n",
        "def softmax(Z):\n",
        "    A = np.exp(Z) / sum(np.exp(Z))\n",
        "    return A\n",
        "\n",
        "def forward_prop(W1, b1, W2, b2, X):\n",
        "    Z1 = W1.dot(X) + b1\n",
        "    A1 = ReLU(Z1)\n",
        "    Z2 = W2.dot(A1) + b2\n",
        "    A2 = softmax(Z2)\n",
        "    return Z1, A1, Z2, A2\n",
        "\n",
        "def ReLU_deriv(Z):\n",
        "    return Z > 0\n",
        "\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
        "    one_hot_Y = one_hot(Y)\n",
        "    dZ2 = A2 - one_hot_Y\n",
        "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
        "    db2 = 1 / m * np.sum(dZ2)\n",
        "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
        "    dW1 = 1 / m * dZ1.dot(X.T)\n",
        "    db1 = 1 / m * np.sum(dZ1)\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "pS6SIaDA9LkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "W1, b1, W2, b2 = init_params()\n",
        "Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_train)\n",
        "dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X_train, Y_train)"
      ],
      "metadata": {
        "id": "6SMJnRC698xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    print(predictions, Y)\n",
        "    return np.sum(predictions == Y) / Y.size\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
        "        if i % 10 == 0:\n",
        "            print(\"Iteration: \", i)\n",
        "            predictions = get_predictions(A2)\n",
        "            print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "28a-y3Vx9ekV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
      ],
      "metadata": {
        "id": "9cd98pg79lC9",
        "outputId": "eaec0340-17b3-4e21-9121-eb1f7d074581",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "[3 1 7 ... 7 7 1] [7 4 0 ... 9 1 3]\n",
            "0.08337280909521554\n",
            "Iteration:  10\n",
            "[4 1 3 ... 7 8 8] [7 4 0 ... 9 1 3]\n",
            "0.1416916679825254\n",
            "Iteration:  20\n",
            "[4 9 3 ... 9 4 8] [7 4 0 ... 9 1 3]\n",
            "0.1966945628717301\n",
            "Iteration:  30\n",
            "[4 9 1 ... 9 4 8] [7 4 0 ... 9 1 3]\n",
            "0.26522448549923683\n",
            "Iteration:  40\n",
            "[4 9 6 ... 9 4 8] [7 4 0 ... 9 1 3]\n",
            "0.3274909205747671\n",
            "Iteration:  50\n",
            "[2 9 6 ... 9 1 8] [7 4 0 ... 9 1 3]\n",
            "0.373651244802358\n",
            "Iteration:  60\n",
            "[2 9 6 ... 7 1 8] [7 4 0 ... 9 1 3]\n",
            "0.41712721722195906\n",
            "Iteration:  70\n",
            "[2 9 6 ... 7 1 8] [7 4 0 ... 9 1 3]\n",
            "0.4640244223380178\n",
            "Iteration:  80\n",
            "[2 9 6 ... 7 1 8] [7 4 0 ... 9 1 3]\n",
            "0.50734249171009\n",
            "Iteration:  90\n",
            "[2 9 6 ... 7 1 8] [7 4 0 ... 9 1 3]\n",
            "0.5419758934680773\n",
            "Iteration:  100\n",
            "[7 9 6 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.5727669877361966\n",
            "Iteration:  110\n",
            "[7 9 6 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.5994526027685667\n",
            "Iteration:  120\n",
            "[7 9 6 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.6245591873256487\n",
            "Iteration:  130\n",
            "[7 9 6 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.6463498078846255\n",
            "Iteration:  140\n",
            "[7 9 6 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.6625611874309174\n",
            "Iteration:  150\n",
            "[7 9 6 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.6782462234854466\n",
            "Iteration:  160\n",
            "[7 9 6 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.6940365282383283\n",
            "Iteration:  170\n",
            "[7 9 8 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7057739881046371\n",
            "Iteration:  180\n",
            "[7 9 8 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7170903731775357\n",
            "Iteration:  190\n",
            "[7 9 8 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7274593399652614\n",
            "Iteration:  200\n",
            "[7 9 8 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7369335228169903\n",
            "Iteration:  210\n",
            "[7 9 8 ... 7 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7455129217327228\n",
            "Iteration:  220\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7531449023632822\n",
            "Iteration:  230\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.759461024264435\n",
            "Iteration:  240\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7664087583557029\n",
            "Iteration:  250\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7721459024159166\n",
            "Iteration:  260\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7781462182220117\n",
            "Iteration:  270\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7828833096478762\n",
            "Iteration:  280\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7872519606295069\n",
            "Iteration:  290\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7905152902784357\n",
            "Iteration:  300\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7951471130059476\n",
            "Iteration:  310\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.7987262487499343\n",
            "Iteration:  320\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8030422653823885\n",
            "Iteration:  330\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8064634980788462\n",
            "Iteration:  340\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8105163429654192\n",
            "Iteration:  350\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8134638665192905\n",
            "Iteration:  360\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8166745618190431\n",
            "Iteration:  370\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8191483762303279\n",
            "Iteration:  380\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8215169219432602\n",
            "Iteration:  390\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.823990736354545\n",
            "Iteration:  400\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8260434759724196\n",
            "Iteration:  410\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8284120216853519\n",
            "Iteration:  420\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.829780514763935\n",
            "Iteration:  430\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8319385230801621\n",
            "Iteration:  440\n",
            "[7 9 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8336228222538028\n",
            "Iteration:  450\n",
            "[7 4 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8358334649192063\n",
            "Iteration:  460\n",
            "[7 4 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8372019579977894\n",
            "Iteration:  470\n",
            "[7 4 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.838675719774725\n",
            "Iteration:  480\n",
            "[7 4 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8400442128533081\n",
            "Iteration:  490\n",
            "[7 4 8 ... 9 1 3] [7 4 0 ... 9 1 3]\n",
            "0.8413074372335386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2Y4H8XK9oOm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}